import logging
import os

import openai
from dotenv import load_dotenv
from google.cloud import texttospeech
from moviepy.editor import (
    AudioFileClip,
    ImageClip,
    VideoFileClip,
    concatenate_videoclips,
)
from pydub import AudioSegment

from ai_media_generator.utils import download_file, ensure_directory_exists

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_APPLICATION_CREDENTIALS = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found. Ensure it's set in the .env file.")
if not GOOGLE_APPLICATION_CREDENTIALS:
    raise ValueError("GOOGLE_APPLICATION_CREDENTIALS not found. Ensure it's set in the .env file.")

os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GOOGLE_APPLICATION_CREDENTIALS
openai.api_key = OPENAI_API_KEY


def generate_text(prompt: str) -> str:
    """
    Generates text using OpenAI's ChatGPT.

    Args:
        prompt (str): The user-provided prompt for generating text.

    Returns:
        str: The text generated by ChatGPT.
    """
    ai_response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    return ai_response["choices"][0]["message"]["content"]


def generate_scene_audio_google_tts(scene_text: str, scene_index: int, output_dir: str = "assets/audio/scenes") -> str:
    """
    Generates audio narration for a scene using Google Cloud Text-to-Speech.

    Args:
        scene_text (str): The text to be converted into speech.
        scene_index (int): The scene's index for naming the audio file.
        output_dir (str): The directory where the audio file will be saved.

    Returns:
        str: The path to the generated audio file.
    """
    client = texttospeech.TextToSpeechClient()

    synthesis_input = texttospeech.SynthesisInput(text=scene_text)
    voice = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Wavenet-I",
    )
    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)

    tts_response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)

    ensure_directory_exists(output_dir)
    scene_audio_path = os.path.join(output_dir, f"scene_{scene_index}.mp3")

    temp_path = os.path.join(output_dir, f"temp_scene_{scene_index}.mp3")
    with open(temp_path, "wb") as temp_file:
        temp_file.write(tts_response.audio_content)

    audio = AudioSegment.from_file(temp_path)
    silence = AudioSegment.silent(duration=500)  # 0.5 seconds of silence
    audio_with_pause = audio + silence
    audio_with_pause.export(scene_audio_path, format="mp3")
    os.remove(temp_path)

    return scene_audio_path


def create_video_for_scene(
    image: str, scene_audio_path: str, scene_index: int, output_dir: str = "assets/video/scenes", fps: int = 24
) -> str:
    """
    Creates a video for a single scene using an image and an audio file.

    Args:
        image (str): Path to the image file.
        scene_audio_path (str): Path to the audio file for the scene.
        scene_index (int): The index of the scene for naming the video file.
        output_dir (str): The directory where the video will be saved.
        fps (int): Frames per second for the video.

    Returns:
        str: The path to the created video file.
    """
    ensure_directory_exists(output_dir)

    audio_clip = AudioFileClip(scene_audio_path)
    duration = audio_clip.duration

    video_clip = ImageClip(image).set_duration(duration).set_audio(audio_clip)
    video_clip.fps = fps

    scene_video_output = os.path.join(output_dir, f"scene_{scene_index}.mp4")
    video_clip.write_videofile(scene_video_output, codec="libx264", audio_codec="aac", fps=fps)

    return scene_video_output


def combine_scene_videos(scene_videos: list[str], output_video_path: str = "assets/video/output.mp4") -> str:
    """
    Combines multiple scene videos into a single video.

    Args:
        scene_videos (list[str]): A list of paths to the scene video files.
        output_video_path (str): The path to save the combined video.

    Returns:
        str: The path to the final combined video.
    """
    clips = [VideoFileClip(video) for video in scene_videos]
    final_video = concatenate_videoclips(clips, method="compose")
    ensure_directory_exists(output_video_path)
    final_video.write_videofile(output_video_path, codec="libx264", audio_codec="aac")
    return output_video_path


if __name__ == "__main__":
    user_prompt = input("Enter a prompt: ")

    modified_prompt = (
        f"Using the following input: '{user_prompt}', write a story and divide it into clear scenes. "
        "Each scene should begin with a title in the format 'Scene [number]:' "
        "followed by a vivid description of the key visual moment and characters in the scene. "
        "Make each scene a maximum of two lines long."
    )

    logger.info("Generating story text from ChatGPT...")
    generated_text = generate_text(modified_prompt)
    logger.info(f"Generated Text:\n{generated_text}")

    logger.info("Extracting and preparing scenes...")
    scenes = []
    current_scene_text = []  # type: ignore
    for line in generated_text.split("\n"):
        if line.strip().lower().startswith("scene") or line.strip().lower().startswith("**scene"):
            if current_scene_text:
                scenes.append("\n".join(current_scene_text).strip())
                current_scene_text = []
        else:
            current_scene_text.append(line.strip())
    if current_scene_text:
        scenes.append("\n".join(current_scene_text).strip())

    logger.info(f"Extracted {len(scenes)} scenes.")

    logger.info("Generating audio for each scene...")
    scene_audio_paths = []
    for idx, scene_text in enumerate(scenes, start=1):
        logger.info(f"Generating audio for Scene {idx}: {scene_text}")
        try:
            audio_path = generate_scene_audio_google_tts(scene_text, idx)
            scene_audio_paths.append(audio_path)
        except Exception as e:
            logger.error(f"Error generating audio for Scene {idx}: {e}")

    logger.info("Generating images for each scene...")
    image_paths = []
    for idx, scene_text in enumerate(scenes, start=1):
        try:
            response = openai.Image.create(prompt=scene_text, n=1, size="1024x1024")
            image_url = response["data"][0]["url"]
            output_path = f"assets/images/scene_{idx}.png"
            download_file(image_url, output_path)
            image_paths.append(output_path)
        except openai.error.OpenAIError as e:
            logger.error(f"Error generating image for Scene {idx}: {e}")

    logger.info("Creating individual videos for each scene...")
    scene_video_paths = []
    for idx, (image, audio) in enumerate(zip(image_paths, scene_audio_paths), start=1):
        try:
            logger.info(f"Creating video for Scene {idx}")
            video_path = create_video_for_scene(image, audio, idx)
            scene_video_paths.append(video_path)
        except Exception as e:
            logger.error(f"Error creating video for Scene {idx}: {e}")

    logger.info("Combining all scene videos into a final video...")
    try:
        final_video_path = combine_scene_videos(scene_video_paths)
        logger.info(f"Final video created at {final_video_path}")
    except Exception as e:
        logger.error(f"Error combining videos: {e}")
